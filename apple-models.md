# Apple's Latest Models on Hugging Face

Apple has been actively releasing various AI models on Hugging Face, with several notable collections launched in recent months. Here's a summary of their latest and most significant models:

## 1. MobileCLIP 2 (Latest Release)

MobileCLIP 2 is one of Apple's most recent releases, featuring mobile-friendly image-text models with state-of-the-art zero-shot capabilities. These models are trained on DFNDR-2B dataset and are designed to be efficient for deployment on mobile devices while maintaining high performance.

Key features:
- Mobile-optimized architecture
- State-of-the-art zero-shot image-text capabilities
- Trained on the DFNDR-2B dataset
- Designed for efficient on-device deployment

## 2. FastVLM (Latest Release)

FastVLM is another recent release from Apple, focusing on efficient vision encoding for Vision Language Models. These models are designed to process visual information more efficiently while maintaining high performance in multimodal tasks.

Key features:
- Efficient vision encoding techniques
- Optimized for Vision Language Models
- Reduced computational requirements
- Maintains high performance on vision-language tasks

## 3. DiffuCoder (July 2025)

DiffuCoder is a collection of code generation models released by Apple in July 2025. The collection includes three 7B parameter models:

- **DiffuCoder-7B-cpGRPO**: The most popular variant with 305 likes and 4.4K downloads
- **DiffuCoder-7B-Instruct**: An instruction-tuned version with 47 likes and 6.97K downloads
- **DiffuCoder-7B-Base**: The base model with 22 likes and 278 downloads

These models are based on research described in the paper "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation" (June 2025).

## 4. OpenELM Models (February 2025)

OpenELM is Apple's open Transformer-based language model collection, available in both pretrained and instruction-tuned versions:

**OpenELM Pretrained Models:**
- OpenELM-270M: 0.3B parameters, 1.28K downloads, 75 likes
- OpenELM-450M: 0.5B parameters, 221 downloads, 26 likes
- OpenELM-1_1B: 1B parameters, 140 downloads, 33 likes
- OpenELM-3B: 3B parameters, 521 downloads, 124 likes

**OpenELM Instruct Models:**
- OpenELM-270M-Instruct: 0.3B parameters, 759 downloads, 138 likes
- OpenELM-450M-Instruct: 0.5B parameters, 930 downloads, 47 likes
- OpenELM-1_1B-Instruct: 1B parameters, 408K downloads, 66 likes
- OpenELM-3B-Instruct: 3B parameters, 3.83K downloads, 337 likes

The OpenELM-3B-Instruct model has been particularly popular, receiving 337 likes, while the OpenELM-1_1B-Instruct model has seen the highest number of downloads at over 408,000.

## 5. Other Notable Collections

Apple has also released several other model collections on Hugging Face:

- **DepthPro Models**: State-of-the-art monocular depth estimation
- **DCLM**: State-of-the-art open data language models via dataset curation
- **DFN Models + Data**: State-of-the-art open data CLIP models via dataset curation
- **Core ML Gallery Models**: Optimized models for Apple's Core ML framework
- **AIMv2**: Advanced image models (second version)

## Core ML Integration

Many of Apple's models are also available in Core ML format, optimized for on-device performance on Apple Silicon. These include:
- Core ML Stable Diffusion
- Core ML FastViT
- Core ML Depth Anything
- Core ML Segment Anything 2

These Core ML models are designed to leverage Apple Silicon and minimize memory footprint and power consumption, making them ideal for deployment on Apple devices.

## Datasets

Apple has also released datasets to support AI research and development:
- **FLAIR**: A large image dataset for federated learning
- **DataCompDR**: Improved datasets for training image-text models

## Summary

Apple's latest releases on Hugging Face demonstrate their commitment to open research in various AI domains, with a particular focus on efficient, mobile-friendly models and Core ML optimizations. Their most recent releases include MobileCLIP 2 and FastVLM, with DiffuCoder and OpenELM representing significant contributions to code generation and language modeling respectively.